import os
import json
import argparse
import time
import hashlib
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from pydantic import BaseModel, Field, field_serializer

from langchain_core.tools import BaseTool, ToolException
from langchain_core.messages import SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, AgentType
from langchain_community.agent_toolkits.load_tools import load_tools
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.memory import ConversationBufferMemory
from langchain_community.document_loaders import WebBaseLoader, TextLoader
from langchain_community.utilities import GoogleSearchAPIWrapper, WikipediaAPIWrapper
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS


# Define models for research tracking
class ResearchTopic(BaseModel):
    """A research topic being investigated"""
    id: str
    title: str
    description: str
    created_at: datetime = Field(default_factory=datetime.now)
    sources: List[str] = Field(default_factory=list)
    findings: List[Dict[str, Any]] = Field(default_factory=list)
    
    @field_serializer('created_at')
    def serialize_dt(self, dt: datetime) -> str:
        return dt.isoformat()


class ResearchManager:
    """Manages research topics and findings"""
    
    def __init__(self, storage_dir: str = "research_data"):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        self.current_topic_id: Optional[str] = None
        self.topics: Dict[str, ResearchTopic] = self._load_topics()
        self.vector_db: Optional[FAISS] = None
        
    def _load_topics(self) -> Dict[str, ResearchTopic]:
        """Load all saved research topics"""
        topics = {}
        for file in self.storage_dir.glob("*.json"):
            if file.name.startswith("topic_"):
                with open(file, "r") as f:
                    data = json.load(f)
                    topic = ResearchTopic(**data)
                    topics[topic.id] = topic
        return topics
        
    def create_topic(self, title: str, description: str) -> str:
        """Create a new research topic and return its ID"""
        topic_id = hashlib.md5(f"{title}_{description}".encode()).hexdigest()[:8]
        
        if topic_id in self.topics:
            return topic_id
            
        topic = ResearchTopic(
            id=topic_id,
            title=title,
            description=description
        )
        self.topics[topic_id] = topic
        self.current_topic_id = topic_id
        self._save_topic(topic)
        return topic_id
        
    def add_finding(self, topic_id: str, content: str, source: str) -> bool:
        """Add a new finding to a research topic"""
        if topic_id not in self.topics:
            return False
            
        topic = self.topics[topic_id]
        
        # Add source if not already tracked
        if source not in topic.sources:
            topic.sources.append(source)
            
        # Add finding
        finding = {
            "id": hashlib.md5(content.encode()).hexdigest()[:8],
            "content": content,
            "source": source,
            "timestamp": datetime.now().isoformat()
        }
        
        topic.findings.append(finding)
        self._save_topic(topic)
        return True
        
    def get_topic(self, topic_id: str) -> Optional[Dict]:
        """Get a topic by ID"""
        if topic_id in self.topics:
            return self.topics[topic_id].model_dump()
        return None
        
    def list_topics(self) -> List[Dict]:
        """List all research topics"""
        return [
            {"id": t.id, "title": t.title, "created_at": t.created_at.isoformat()}
            for t in self.topics.values()
        ]
        
    def get_findings(self, topic_id: str) -> List[Dict]:
        """Get all findings for a topic"""
        if topic_id in self.topics:
            return self.topics[topic_id].findings
        return []
        
    def _save_topic(self, topic: ResearchTopic) -> None:
        """Save a topic to disk"""
        file_path = self.storage_dir / f"topic_{topic.id}.json"
        with open(file_path, "w") as f:
            json.dump(topic.model_dump(), f, indent=2)
            
    def create_vector_db(self, topic_id: str) -> bool:
        """Create a vector DB from the findings of a topic"""
        if topic_id not in self.topics:
            return False
            
        topic = self.topics[topic_id]
        documents = []
        
        # Create documents from findings
        for finding in topic.findings:
            documents.append({
                "page_content": finding["content"],
                "metadata": {
                    "source": finding["source"],
                    "id": finding["id"]
                }
            })
            
        if not documents:
            return False
            
        # Create embeddings and store in vector DB
        embeddings = OpenAIEmbeddings()
        self.vector_db = FAISS.from_documents(documents, embeddings)
        return True
        
    def query_findings(self, query: str, k: int = 3) -> List[Dict]:
        """Query the vector DB for relevant findings"""
        if not self.vector_db:
            return []
            
        results = self.vector_db.similarity_search(query, k=k)
        return [
            {
                "content": doc.page_content,
                "source": doc.metadata.get("source", "Unknown"),
                "id": doc.metadata.get("id", "Unknown")
            }
            for doc in results
        ]


# Custom Tools for Research Agent
class WebSearchTool(BaseTool):
    name: str = "web_search"
    description = "Search for information on the web using Google"
    
    def __init__(self):
        super().__init__()
        load_dotenv()
        self.search = GoogleSearchAPIWrapper()
        
    def _run(self, query: str) -> str:
        """Run Google search and return results"""
        try:
            results = self.search.results(query, num_results=5)
            formatted_results = []
            
            for i, result in enumerate(results, 1):
                title = result.get("title", "No title")
                link = result.get("link", "No link")
                snippet = result.get("snippet", "No snippet")
                formatted_results.append(f"{i}. {title}\n   URL: {link}\n   {snippet}\n")
                
            return "Search Results:\n\n" + "\n".join(formatted_results)
        except Exception as e:
            raise ToolException(f"Error searching the web: {str(e)}")
            
    def _arun(self, query: str):
        raise NotImplementedError("Async not implemented")


class WebPageReaderTool(BaseTool):
    name = "webpage_reader"
    description = "Read and extract the main content from a web page URL"
    
    def _run(self, url: str) -> str:
        """Extract and return the main content from a web page"""
        try:
            loader = WebBaseLoader(url)
            docs = loader.load()
            
            # Join all document content
            full_content = "\n\n".join(doc.page_content for doc in docs)
            
            # Split if too large
            if len(full_content) > 8000:
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=8000,
                    chunk_overlap=200
                )
                splits = text_splitter.split_text(full_content)
                return f"Content (truncated, {len(splits)} parts):\n\n{splits[0]}\n\n[Content truncated due to length...]"
            
            return f"Content from {url}:\n\n{full_content}"
        except Exception as e:
            raise ToolException(f"Error reading web page: {str(e)}")
            
    def _arun(self, url: str):
        raise NotImplementedError("Async not implemented")


class WikipediaResearchTool(BaseTool):
    name = "wikipedia_research"
    description = "Search Wikipedia and get detailed information on a topic"
    
    def __init__(self):
        super().__init__()
        self.wikipedia = WikipediaAPIWrapper(top_k_results=3)
        
    def _run(self, query: str) -> str:
        """Search Wikipedia and return results"""
        try:
            result = self.wikipedia.run(query)
            return f"Wikipedia information on '{query}':\n\n{result}"
        except Exception as e:
            raise ToolException(f"Error searching Wikipedia: {str(e)}")
            
    def _arun(self, query: str):
        raise NotImplementedError("Async not implemented")


class TopicManagementTool(BaseTool):
    name = "topic_management"
    description = "Manage research topics. Use this to create a new topic, list topics, or get topic details."
    
    def __init__(self, research_manager: ResearchManager):
        super().__init__()
        self.manager = research_manager
        
    def _run(self, command: str) -> str:
        """Handle topic management commands"""
        try:
            parts = command.strip().split(' ', 1)
            cmd = parts[0].lower()
            
            if cmd == "create" and len(parts) > 1:
                # Format: create Title | Description
                title_desc = parts[1].split('|', 1)
                if len(title_desc) != 2:
                    return "Error: Format should be 'create Title | Description'"
                    
                title = title_desc[0].strip()
                description = title_desc[1].strip()
                topic_id = self.manager.create_topic(title, description)
                return f"Created research topic '{title}' with ID: {topic_id}"
                
            elif cmd == "list":
                topics = self.manager.list_topics()
                if not topics:
                    return "No research topics found"
                    
                result = "Research Topics:\n\n"
                for topic in topics:
                    result += f"- {topic['title']} (ID: {topic['id']}, Created: {topic['created_at']})\n"
                return result
                
            elif cmd == "get" and len(parts) > 1:
                topic_id = parts[1].strip()
                topic = self.manager.get_topic(topic_id)
                
                if not topic:
                    return f"Topic with ID '{topic_id}' not found"
                    
                result = f"Research Topic: {topic['title']}\n"
                result += f"ID: {topic['id']}\n"
                result += f"Created: {topic['created_at']}\n"
                result += f"Description: {topic['description']}\n\n"
                
                if topic['sources']:
                    result += "Sources:\n"
                    for source in topic['sources']:
                        result += f"- {source}\n"
                        
                result += f"\nFindings: {len(topic['findings'])} items"
                return result
                
            else:
                return ("Error: Unknown command. Use one of:\n"
                        "- create Title | Description\n"
                        "- list\n"
                        "- get [topic_id]")
                        
        except Exception as e:
            raise ToolException(f"Error in topic management: {str(e)}")
            
    def _arun(self, command: str):
        raise NotImplementedError("Async not implemented")


class FindingsManagementTool(BaseTool):
    name = "findings_management"
    description = "Add or retrieve research findings for a topic"
    
    def __init__(self, research_manager: ResearchManager):
        super().__init__()
        self.manager = research_manager
        
    def _run(self, command: str) -> str:
        """Handle findings management commands"""
        try:
            parts = command.strip().split(' ', 1)
            if len(parts) != 2:
                return "Error: Command format incorrect"
                
            cmd = parts[0].lower()
            
            if cmd == "add":
                # Format: add topic_id | source | content
                params = parts[1].split('|', 2)
                if len(params) != 3:
                    return "Error: Format should be 'add topic_id | source | content'"
                    
                topic_id = params[0].strip()
                source = params[1].strip()
                content = params[2].strip()
                
                if self.manager.add_finding(topic_id, content, source):
                    return f"Added new finding to topic {topic_id}"
                else:
                    return f"Error: Topic with ID {topic_id} not found"
                    
            elif cmd == "list":
                topic_id = parts[1].strip()
                findings = self.manager.get_findings(topic_id)
                
                if not findings:
                    return f"No findings for topic {topic_id}"
                    
                result = f"Findings for Topic {topic_id}:\n\n"
                for i, finding in enumerate(findings, 1):
                    result += f"{i}. Source: {finding['source']}\n"
                    content_preview = finding['content'][:100] + "..." if len(finding['content']) > 100 else finding['content']
                    result += f"   {content_preview}\n\n"
                    
                return result
                
            elif cmd == "query":
                # Format: query query_text
                query = parts[1].strip()
                if not self.manager.vector_db:
                    if self.manager.current_topic_id:
                        self.manager.create_vector_db(self.manager.current_topic_id)
                    else:
                        return "Error: No active research topic to query"
                        
                results = self.manager.query_findings(query)
                
                if not results:
                    return "No relevant findings found"
                    
                result = "Relevant Findings:\n\n"
                for i, finding in enumerate(results, 1):
                    result += f"{i}. Source: {finding['source']}\n"
                    result += f"   {finding['content']}\n\n"
                    
                return result
                
            else:
                return ("Error: Unknown command. Use one of:\n"
                        "- add topic_id | source | content\n"
                        "- list topic_id\n"
                        "- query search_query")
                        
        except Exception as e:
            raise ToolException(f"Error in findings management: {str(e)}")
            
    def _arun(self, command: str):
        raise NotImplementedError("Async not implemented")


class SummarizerTool(BaseTool):
    name = "summarizer"
    description = "Summarize text content into key points"
    
    def __init__(self, llm):
        super().__init__()
        self.llm = llm
        
    def _run(self, text: str) -> str:
        """Summarize the provided text"""
        try:
            if len(text) < 100:
                return "Text is too short to summarize."
                
            # Use the LLM to generate a summary
            prompt = (
                f"Please summarize the following text into key points:\n\n{text}\n\n"
                "Summary (key points):"
            )
            summary = self.llm.invoke(prompt).content
            
            return f"Summary:\n\n{summary}"
        except Exception as e:
            raise ToolException(f"Error summarizing content: {str(e)}")
            
    def _arun(self, text: str):
        raise NotImplementedError("Async not implemented")


def build_research_agent(
    model_name: str = "gemini-2.0-flash",
    *,
    temperature: float = 0.2,
    verbose: bool = True,
):
    """Build and return a research assistant agent"""
    load_dotenv()
    
    # Initialize the research manager
    research_manager = ResearchManager()
    
    # Initialize the LLM
    if "gemini" in model_name.lower():
        if not os.environ.get("GOOGLE_API_KEY"):
            raise EnvironmentError("GOOGLE_API_KEY environment variable is not set.")
        llm = ChatGoogleGenerativeAI(model=model_name, temperature=temperature)
    else:
        if not os.environ.get("OPENAI_API_KEY"):
            raise EnvironmentError("OPENAI_API_KEY environment variable is not set.")
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(model_name=model_name, temperature=temperature)
    
    # Create memory for the agent
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    
    # Create the tools
    tools = [
        WebSearchTool(),
        WikipediaResearchTool(),
        WebPageReaderTool(),
        TopicManagementTool(research_manager),
        FindingsManagementTool(research_manager),
        SummarizerTool(llm)
    ]
    
    # System message to guide the agent
    system_message = SystemMessage(
        content="""You are a Research Assistant Agent. Your job is to help users conduct thorough research on topics.

You can:
1. Search the web and Wikipedia for information
2. Read and extract content from web pages
3. Create and manage research topics
4. Add findings to research topics
5. Retrieve and query research findings
6. Summarize content into key points

When conducting research:
- First, create a research topic if one doesn't exist
- Search for relevant information using the web_search and wikipedia_research tools
- Read important web pages using the webpage_reader tool
- Summarize content using the summarizer tool
- Save important findings using the findings_management tool
- Help the user organize and make sense of the information collected

Always be methodical and thorough in your research approach.
"""
    )
    
    # Create the agent
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
        verbose=verbose,
        memory=memory,
        agent_kwargs={"system_message": system_message},
        handle_parsing_errors=True,
        max_iterations=8,
    )
    
    return agent, research_manager


def main():
    parser = argparse.ArgumentParser(description="Research Assistant Agent")
    parser.add_argument(
        "--model",
        default="gemini-2.0-flash",
        help="LLM model to use (gemini-2.0-flash or gpt-4-turbo)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose mode to see agent's reasoning",
    )
    args = parser.parse_args()
    
    agent, research_manager = build_research_agent(model_name=args.model, verbose=args.verbose)
    
    print("=== Research Assistant Agent ===")
    print("This agent can help you conduct research by:")
    print("- Searching the web and Wikipedia")
    print("- Reading and extracting content from web pages")
    print("- Creating and managing research topics")
    print("- Organizing research findings")
    print("- Summarizing information")
    print("\nExample commands:")
    print("- 'Research quantum computing basics'")
    print("- 'Create a topic about climate change solutions'")
    print("- 'Summarize what we've found so far'")
    print("\nType 'exit' to quit.")
    
    while True:
        try:
            user_input = input("\nUser> ")
        except (EOFError, KeyboardInterrupt):
            print()  # newline on Ctrl‑C / Ctrl‑D
            break
            
        if user_input.strip().lower() in {"exit", "quit", "q"}:
            break
            
        try:
            response = agent.invoke({"input": user_input})
            print(f"Agent> {response['output']}")
        except Exception as err:
            print(f"[⚠️] Agent error: {err}")
            continue


if __name__ == "__main__":
    main()